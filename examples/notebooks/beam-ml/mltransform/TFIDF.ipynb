{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DItny3PaJmuW"
      },
      "outputs": [],
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/apache/beam.git\n",
        "! cd beam/sdks/python\n",
        "! pip install beam/sdks/python\n",
        "! pip install tensorflow-transform --quiet"
      ],
      "metadata": {
        "id": "EB1MnUtaJrdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use TD-IDF to weight terms\n",
        "\n",
        "[TF-IDF](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.transforms.tft.html#apache_beam.ml.transforms.tft.ComputeAndApplyVocabulary) (Term Frequency-Inverse Document Frequency) is a numerical statistic used in text processing to reflect how important a word is to a document in a collection or corpus. It balances the frequency of a word in a document against its frequency in the entire corpus, giving higher value to more specific terms.\n",
        "\n",
        "Use `TF-IDF` with `MLTransform`.\n",
        "\n",
        "1. Compute the vocabulary of the dataset by using `ComputeAndApplyVocabulary`.\n",
        "2. Use the output of `ComputeAndApplyVocabulary` to calculate the `TF-IDF` weights.\n",
        "\n",
        "In this notebook, `MLTransform` will be run in `write` mode and `read` mode.\n",
        "\n",
        "#### MLTransform in write mode.\n",
        "\n",
        "In write mode, `MLTransform` will generate artifacts such as `min` and `max` of the entire dataset and then uses these generated artifacts to scale the entire dataset. This workflow is useful for data going to train an ML model.\n",
        "\n",
        "#### MLTransform in read mode.\n",
        "\n",
        "In read mode, `MLTransform` will use the generated artifacts from write mode and then uses those artifacts to scale the entire dataset.\n",
        "\n",
        "For more information about using `MLTransform`, see [Preprocess data with MLTransform](https://beam.apache.org/documentation/ml/preprocess-data/) in the Apache Beam documentation\n"
      ],
      "metadata": {
        "id": "nI-iJvyRJxHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the required modules\n",
        "\n",
        "To use `MLTransfrom`, install tensorflow_transform and the Apache Beam SDK version 2.53.0 or later"
      ],
      "metadata": {
        "id": "W095gdPDJu1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import apache_beam as beam\n",
        "from apache_beam.ml.transforms.base import MLTransform\n",
        "from apache_beam.ml.transforms.tft import TFIDF, ComputeAndApplyVocabulary"
      ],
      "metadata": {
        "id": "dkJJKaW4Lz0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_location = tempfile.mkdtemp(prefix='TFIDF_')\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        'feature': ['I', 'love', 'pie']\n",
        "    },\n",
        "    {\n",
        "        'feature': ['I', 'love', 'going', 'to', 'the', 'park']\n",
        "    }\n",
        "]\n",
        "\n",
        "test_data = [\n",
        "    {\n",
        "        'feature': ['I', 'love', 'dogs']\n",
        "    },\n",
        "    {\n",
        "        'feature': ['Dogs', 'are', 'running', 'in', 'the', 'park' ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ASOnFouSPwzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF output\n",
        "\n",
        "`TF-IDF` produces two output columns for a given input. For example, if you input `feature`, the output column names in the dictionary are `feature_vocab_index` and `feature_tfidf_weight`.\n",
        "\n",
        "- `vocab_index`: indices of the words computed in the `ComputeAndApplyVocabulary` transform.\n",
        "- `tfidif_weight`: the weight for each vocabulary index. The weight represents how important the word present at that `vocab_index` is to the document.\n"
      ],
      "metadata": {
        "id": "XE2qjAY0Rgva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write mode\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = pipeline | \"CreateData\" >> beam.Create(data)\n",
        "\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location\n",
        "                     ).with_transform(ComputeAndApplyVocabulary(columns=['feature'])\n",
        "                     ).with_transform(TFIDF(columns=['feature']))\n",
        "  )\n",
        "  transformed_pcoll | \"Print\" >> beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu3P4rTZQZJP",
        "outputId": "1174bd9b-cb10-4d07-e87e-37a01f5e06c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
            "WARNING:absl:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
            "WARNING:absl:You are outputting instance dicts from `TransformDataset` which will not provide optimal performance. Consider setting  `output_record_batches=True` to upgrade to the TFXIO format (Apache Arrow RecordBatch). Encoding functionality in this module works with both formats.\n",
            "WARNING:absl:Analyzer (tfidf/sum/temporary_analyzer_output/PlaceholderWithDefault:0) node's cache key varies on repeated tracing. This warning is safe to ignore if you either specify `name` for all analyzers or if the order in which they are invoked is deterministic. If not, please file a bug with details.\n",
            "WARNING:absl:Analyzer (tfidf/sum/temporary_analyzer_output/PlaceholderWithDefault:0) node's cache key varies on repeated tracing. This warning is safe to ignore if you either specify `name` for all analyzers or if the order in which they are invoked is deterministic. If not, please file a bug with details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(feature=array([1, 0, 4]), feature_tfidf_weight=array([0.33333334, 0.33333334, 0.4684884 ], dtype=float32), feature_vocab_index=array([0, 1, 4]))\n",
            "Row(feature=array([1, 0, 6, 2, 3, 5]), feature_tfidf_weight=array([0.16666667, 0.16666667, 0.2342442 , 0.2342442 , 0.2342442 ,\n",
            "       0.2342442 ], dtype=float32), feature_vocab_index=array([0, 1, 2, 3, 5, 6]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read mode\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = pipeline | \"CreateData\" >> beam.Create(test_data)\n",
        "\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(read_artifact_location=artifact_location)\n",
        "  )\n",
        "  transformed_pcoll | \"Print\" >> beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMrUCjHTkJj",
        "outputId": "7dd99900-7480-46a5-dd8c-c79cbed297b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
            "WARNING:absl:You are outputting instance dicts from `TransformDataset` which will not provide optimal performance. Consider setting  `output_record_batches=True` to upgrade to the TFXIO format (Apache Arrow RecordBatch). Encoding functionality in this module works with both formats.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(feature=array([ 1,  0, -1]), feature_tfidf_weight=array([0.33333334, 0.33333334, 0.4684884 ], dtype=float32), feature_vocab_index=array([0, 1, 6]))\n",
            "Row(feature=array([-1, -1, -1, -1,  3,  5]), feature_tfidf_weight=array([0.2342442, 0.2342442, 0.9369768], dtype=float32), feature_vocab_index=array([3, 5, 6]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When processing text data using TF-IDF (Term Frequency-Inverse Document Frequency), any term not found in the predefined vocabulary (termed 'out-of-vocabulary' or OOV) is assigned a unique identifier equal to the length of the vocabulary plus one. Despite being outside the established vocabulary, these OOV terms are still evaluated in the TF-IDF transformation. This approach ensures that all terms in the data, even those not initially recognized, are accounted for and given appropriate weights in the TF-IDF scheme, enabling comprehensive and nuanced text analysis.\n",
        "\n",
        "\n",
        "**NOTE**: For TFIDF, a Vocabulary must be generated and each word is assigned to an index because TFIDF accepts int inputs."
      ],
      "metadata": {
        "id": "U7HCWmtaUyqe"
      }
    }
  ]
}