{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "muiqKarukWj0"
      },
      "outputs": [],
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate text embeddings by using the Vertex AI API\n",
        "\n",
        "## Text Embeddings\n",
        "\n",
        "Text embeddings are a way of representing text as numerical vectors. This allows computers to understand and process text data, which is essential for many natural language processing (NLP) tasks.\n",
        "\n",
        "### Uses of text embeddings\n",
        "By converting text into numerical vectors, text embeddings make it possible for computers to process and analyze text data. This enables a wide range of NLP tasks, including:\n",
        "\n",
        "* Semantic search: Finding documents or passages that are relevant to a query, even if the query doesn't use the exact same words as the documents.\n",
        "* Text classification: Categorzing text data into different classes, such as spam or not spam, or positive sentiment or negative sentiment.\n",
        "* Machine translation: Translating text from one language to another while preserving the meaning.\n",
        "* Text summarization: Creating shorter summaries of longer pieces of text.\n",
        "\n",
        "In this notebook, we will use Apache Beam's `MLTransform` to embeddings on the text data.\n",
        "\n",
        "Vertex AI provides an API that you can use to generate text embeddings that use Googleâ€™s large generative AI models. For more information, see [Get text embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings). To generate text embeddings by using the Vertex AI text-embeddings API, use `MLTransform` with the `VertexAITextEmbeddings` class to specify the model configuration.\n",
        "\n",
        "For more information about using `MLTransform`, see [Preprocess data with MLTransform](https://beam.apache.org/documentation/ml/preprocess-data/) in the Apache Beam documentation.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "To use the Vertex AI text-embeddings API, complete the following prerequisites:\n",
        "\n",
        "* Install the `google-cloud-aiplatform` Python package.\n",
        "* Do one of the following tasks:\n",
        "  * Configure Credentials for your Google cloud project. For more information, see [Google Auth Library for Python](https://googleapis.dev/python/google-auth/latest/reference/google.auth.html#module-google.auth).\n",
        "  * Store the path to a service account JSON file by using the [GOOGLE_APPLICATION_CREDENTIALS](https://cloud.google.com/docs/authentication/application-default-credentials#GAC) environment variable."
      ],
      "metadata": {
        "id": "bkpSCGCWlqAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use your Google Cloud account, authenticate this notebook."
      ],
      "metadata": {
        "id": "W29FgO5Qv2ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# TODO: Remove the project name before merging.\n",
        "project = 'google.com:clouddfe' # Replace with a valid project id."
      ],
      "metadata": {
        "id": "nYyyGYt3licq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n",
        " Install Apache Beam and the dependencies required for the Vertex AI text-embeddings API."
      ],
      "metadata": {
        "id": "UQROd16ZDN5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/apache/beam.git\n",
        "! cd beam/sdks/python\n",
        "! pip install beam/sdks/python[gcp]"
      ],
      "metadata": {
        "id": "BTxob7d5DLBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Import the required modules\n",
        "\n"
      ],
      "metadata": {
        "id": "JUoiSeRpn4GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import apache_beam as beam\n",
        "from apache_beam.ml.transforms.base import MLTransform\n",
        "from apache_beam.ml.transforms.embeddings.vertex_ai import VertexAITextEmbeddings"
      ],
      "metadata": {
        "id": "SkMhR7H6n1P0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MLTransform in write mode\n",
        "\n",
        "In `write` mode, `MLTransform` saves the transforms and their attributes to an artifact location. These transforms are reused in `read` mode."
      ],
      "metadata": {
        "id": "cokOaX2kzyke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_location = tempfile.mkdtemp(prefix='vertex_ai')\n",
        "\n",
        "# Use the latest text embedding model from the Vertex AI API documentation\n",
        "# https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings\n",
        "text_embedding_model_name = 'textembedding-gecko@latest'\n",
        "\n",
        "# Generate text embedding on the sentences.\n",
        "content = [{ 'x' : 'I would like embeddings for this text'}, {'x' : 'Hello world'},\n",
        "           {\n",
        "               'x': 'The Dog is running in the park.'\n",
        "           }]\n",
        "\n",
        "# helper function that returns a dict containing only first\n",
        "#10 elements of generated embeddings.\n",
        "def truncate_embeddings(d):\n",
        "  for key in d.keys():\n",
        "    d[key] = d[key][:10]\n",
        "  return d"
      ],
      "metadata": {
        "id": "be-vR159pylF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `MLTransform` function processes a dictionary containing column names and their corresponding text data. For each sentence, it generates a list of embeddings. This pipeline generates text embeddings based on the input sentences by calling the Vertex AI text-embeddings API for online prediction."
      ],
      "metadata": {
        "id": "jkDydrU2t2N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_transform = VertexAITextEmbeddings(\n",
        "        model_name=text_embedding_model_name, columns=['x'], project=project)\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location).with_transform(embedding_transform))\n",
        "\n",
        "  # Show just the first 10 elements of the embeddings to prevent clutter in the output.\n",
        "  transformed_pcoll | beam.Map(truncate_embeddings) | 'LogOutput' >> beam.Map(print)\n",
        "\n",
        "  transformed_pcoll | \"PrintEmbeddingShape\" >> beam.Map(lambda x: print(f\"Embedding shape: {len(x['x'])}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQGm1be3p7lM",
        "outputId": "b41172ca-1c73-4952-ca87-bfe45ca88a6c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': [0.041293490678071976, -0.010302993468940258, -0.048611514270305634, -0.01360565796494484, 0.06441926211118698, 0.022573700174689293, 0.016446372494101524, -0.033894773572683334, 0.004581860266625881, 0.060710687190294266]}\n",
            "Embedding shape: 10\n",
            "{'x': [0.05889148637652397, -0.0046180677600204945, -0.06738516688346863, -0.012708292342722416, 0.06461101770401001, 0.025648491457104683, 0.023468563333153725, -0.039828114211559296, -0.009968819096684456, 0.050098177045583725]}\n",
            "Embedding shape: 10\n",
            "{'x': [0.04683901369571686, -0.013076924718916416, -0.082594133913517, -0.01227626483887434, 0.00417641457170248, -0.024504298344254494, 0.04282262548804283, -0.0009824123699218035, -0.02860993705689907, 0.01609829254448414]}\n",
            "Embedding shape: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MLTransform in read mode\n",
        "\n",
        "In `read` mode, `MLTransform` uses the artifacts saved during `write` mode. In this example, the transform and its attributes are loaded from the saved artifacts. You don't need to specify artifacts again during `read` mode.\n",
        "\n",
        "In this way, `MLTransform` provides consistent preprocessing steps for training and inference workloads."
      ],
      "metadata": {
        "id": "JLkmQkiLx_6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_content = [\n",
        "    {\n",
        "        'x': 'This is a test sentence'\n",
        "    },\n",
        "    {\n",
        "        'x': 'The park is full of dogs'\n",
        "    },\n",
        "]\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(test_content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(read_artifact_location=artifact_location))\n",
        "\n",
        "  transformed_pcoll | beam.Map(truncate_embeddings) | 'LogOutput' >> beam.Map(print)\n"
      ],
      "metadata": {
        "id": "r8Y5vgfLx_Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cbf6b7-5c31-4efa-90cf-7a8a108ecc77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': [0.04782044142484665, -0.010078949853777885, -0.05793016776442528, -0.026060665026307106, 0.05756739526987076, 0.02292264811694622, 0.014818413183093071, -0.03718176111578941, -0.005486017093062401, 0.04709304869174957]}\n",
            "{'x': [0.042911216616630554, -0.007554919924587011, -0.08996245265007019, -0.02607591263949871, 0.0008614308317191899, -0.023671219125390053, 0.03999944031238556, -0.02983051724731922, -0.015057179145514965, 0.022963201627135277]}\n"
          ]
        }
      ]
    }
  ]
}