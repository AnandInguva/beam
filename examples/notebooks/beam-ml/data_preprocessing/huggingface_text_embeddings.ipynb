{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UmEFwsNs1OES"
      },
      "outputs": [],
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Text Embeddings by using Hugging Face Hub models\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/apache/beam/blob/master/examples/notebooks/beam-ml/data_preprocessing/huggingface_text_embeddings.ipynb.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/colab_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/data_preprocessing/huggingface_text_embeddings.ipynb\"><img src=\"https://raw.githubusercontent.com/google/or-tools/main/tools/github_32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "ZUSiAR62SgO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Text Embeddings\n",
        "\n",
        "Text embeddings are a way of representing text as numerical vectors. This allows computers to understand and process text data, which is essential for many natural language processing (NLP) tasks.\n",
        "\n",
        "### Uses of text embeddings\n",
        "By converting text into numerical vectors, text embeddings make it possible for computers to process and analyze text data. This enables a wide range of NLP tasks, including:\n",
        "\n",
        "* Semantic search: Finding documents or passages that are relevant to a query, even if the query doesn't use the exact same words as the documents.\n",
        "* Text classification: Categorizng text data into different classes, such as spam or not spam, or positive sentiment or negative sentiment.\n",
        "* Machine translation: Translating text from one language to another while preserving the meaning.\n",
        "* Text summarization: Creating shorter summaries of longer pieces of text.\n",
        "\n",
        "In this notebook, we will use Apache Beam's `MLTransform` to generate embeddings from text data.\n",
        "\n",
        "Hugging Face's [`SentenceTransformers`](https://huggingface.co/sentence-transformers) framework uses Python to generate sentence, text, and image embeddings.\n",
        "\n",
        "To generate text embeddings that use Hugging Face models and `MLTransform`, use `SentenceTransformerEmbeddings` to specify the model configuration.\n",
        "\n",
        "To use `SentenceTransformerEmbeddings`, first install the `the sentence-transformers` package."
      ],
      "metadata": {
        "id": "yvVIEhF01ZWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies\n",
        " Install Apache Beam and the dependencies needed to work with Hugging Face embeddings."
      ],
      "metadata": {
        "id": "jqYXaBJ821Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/apache/beam.git\n",
        "! cd beam/sdks/python\n",
        "! pip install beam/sdks/python\n",
        "! pip install sentence-transformers"
      ],
      "metadata": {
        "id": "shzCUrZI1XhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import apache_beam as beam\n",
        "from apache_beam.ml.transforms.base import MLTransform\n",
        "from apache_beam.ml.transforms.embeddings.huggingface import SentenceTransformerEmbeddings"
      ],
      "metadata": {
        "id": "jVxSi2jS3M3b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MLTransform in write mode\n",
        "\n",
        "In `write` mode, `MLTransform` saves the transforms and their attributes to an artifact location. These transforms are used when you run `MLTransform` in `read` mode.\n",
        "\n",
        "For more information about using `MLTransform`, see [Preprocess data with MLTransform](https://beam.apache.org/documentation/ml/preprocess-data/) in the Apache Beam documentation."
      ],
      "metadata": {
        "id": "kXDM8C7d3nPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate text embeddings with `MLTransform`, the following pipeline uses the model `sentence-transformers/all-MiniLM-L6-v2` and the text inputs from the Hugging Face blog [Getting Started With Embeddings](https://huggingface.co/blog/getting-started-with-embeddings)."
      ],
      "metadata": {
        "id": "Dbkmu3HP6Kql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = [\n",
        "    {'x': 'How do I get a replacement Medicare card?'},\n",
        "    {'x': 'What is the monthly premium for Medicare Part B?'},\n",
        "    {'x': 'How do I terminate my Medicare Part B (medical insurance)?'},\n",
        "    {'x': 'How do I sign up for Medicare?'},\n",
        "    {'x': 'Can I sign up for Medicare Part B if I am working and have health insurance through an employer?'},\n",
        "    {'x': 'How do I sign up for Medicare Part B if I already have Part A?'},\n",
        "    {'x': 'What are Medicare late enrollment penalties?'},\n",
        "    {'x': 'What is Medicare and who can get it?'},\n",
        "    {'x': 'How can I get help with my Medicare Part A and Part B premiums?'},\n",
        "    {'x': 'What are the different parts of Medicare?'},\n",
        "    {'x': 'Will my Medicare premiums be higher because of my higher income?'},\n",
        "    {'x': 'What is TRICARE ?'},\n",
        "    {'x': \"Should I sign up for Medicare Part B if I have Veterans' Benefits?\"}\n",
        "]\n",
        "\n",
        "\n",
        "# helper function that returns a dict containing only first\n",
        "#10 elements of generated embeddings.\n",
        "def truncate_embeddings(d):\n",
        "  for key in d.keys():\n",
        "    d[key] = d[key][:10]\n",
        "  return d"
      ],
      "metadata": {
        "id": "LCTUs8F73iDg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_location_minilm = tempfile.mkdtemp(prefix='huggingface_')\n",
        "text_embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "embedding_transform = SentenceTransformerEmbeddings(\n",
        "        model_name=text_embedding_model_name, columns=['x'])\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location_minilm).with_transform(embedding_transform))\n",
        "\n",
        "  transformed_pcoll | beam.Map(truncate_embeddings) | 'LogOutput' >> beam.Map(print)\n",
        "\n",
        "  transformed_pcoll | \"PrintEmbeddingShape\" >> beam.Map(lambda x: print(f\"Embedding shape: {len(x['x'])}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF6izkN134sf",
        "outputId": "740f450a-dc9c-4c9d-f4fb-8ef27cca3d74"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': [-0.023889463394880295, 0.05525851249694824, -0.011654896661639214, -0.03341428190469742, -0.012260555289685726, -0.024872763082385063, -0.01266342680901289, 0.025345895439386368, 0.01850851997733116, -0.08350814878940582]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.01268761046230793, 0.04687413573265076, -0.010502150282263756, -0.020383981987833977, -0.01336114201694727, 0.04232167452573776, 0.016627851873636246, -0.004099288955330849, -0.0026070312596857548, -0.010187783278524876]}\n",
            "Embedding shape: 10\n",
            "{'x': [0.0004943296662531793, 0.11941202729940414, 0.005229473114013672, -0.09273427724838257, 0.007772865705192089, -0.005324989557266235, 0.03450643643736839, -0.05198145657777786, -0.006264965515583754, -0.006110507529228926]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.029711326584219933, 0.02329839952290058, -0.05704096704721451, -0.01218305341899395, -0.013710316270589828, 0.02979600988328457, 0.0637386366724968, 0.0011010386515408754, -0.04512352868914604, -0.040747467428445816]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.02562842145562172, 0.070388562977314, -0.017379559576511383, -0.0565667562186718, 0.02857644483447075, 0.052822552621364594, 0.06706249713897705, -0.05261750519275665, -0.054702047258615494, -0.11623040586709976]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.022656124085187912, 0.021159743890166283, 0.0051048519089818, -0.04649421200156212, 0.009073587134480476, 0.04149482399225235, 0.0542682446539402, -0.02418488636612892, -0.013482789508998394, -0.07596635073423386]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.0029113641940057278, 0.060791268944740295, -0.009175681509077549, -0.006133317016065121, 0.04049248993396759, 0.036593958735466, 0.002054463606327772, -0.03134453296661377, 0.03180575743317604, -0.02349487692117691]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.08052562177181244, 0.05988812819123268, -0.048846807330846786, -0.040176115930080414, -0.06334187835454941, 0.04184781387448311, 0.11904510855674744, 0.010651882737874985, -0.030094878748059273, -0.004561211448162794]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.0343877375125885, 0.07250142097473145, 0.01443990133702755, -0.03669498860836029, 0.014018685556948185, 0.06307007372379303, 0.03468254581093788, -0.014530746266245842, -0.05986189469695091, -0.04538322612643242]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.005963834468275309, 0.025043703615665436, -0.003182061715051532, -0.025242920964956284, -0.0398230254650116, -0.012771873734891415, 0.0447133406996727, 0.014535333029925823, -0.03821341320872307, -0.04114910215139389]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.039007965475320816, -0.010609461925923824, -0.007382705342024565, -0.050189778208732605, -0.0025175788905471563, -0.0416409894824028, 0.02696940489113331, -0.014800631441175938, -0.014126974157989025, -0.061636749655008316]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.09598278254270554, -0.06301165372133255, -0.11690578609704971, -0.05907457321882248, -0.05132286250591278, -0.0034391973167657852, 0.018687350675463676, 0.006543711293488741, -0.04905705526471138, -0.031649429351091385]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.011600406840443611, 0.05651004612445831, 0.016623979434370995, -0.09469003975391388, -0.009865491650998592, 0.07234735041856766, 0.04412448778748512, -0.0411749929189682, -0.04212445020675659, -0.10263106226921082]}\n",
            "Embedding shape: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also pass additional arguments that are supported by `sentence-transformer` models, such as `convert_to_numpy=False`. These arguments are passed as a `dict` to the `SentenceTransformerEmbeddings` transform by using the `inference_args` parameter.\n",
        "\n",
        "By passing `convert_to_numpy=False`, the output will contain `torch.Tensor`s."
      ],
      "metadata": {
        "id": "1MFom0PW_vRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_location_minilm_with_inference_args = tempfile.mkdtemp(prefix='huggingface_')\n",
        "\n",
        "embedding_transform = SentenceTransformerEmbeddings(\n",
        "        model_name=text_embedding_model_name, columns=['x'],\n",
        "        inference_args={'convert_to_numpy': False}\n",
        "        )\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location_minilm_with_inference_args).with_transform(embedding_transform))\n",
        "\n",
        "  # The outputs are in the Pytorch tensor type.\n",
        "  transformed_pcoll | 'LogOutput' >> beam.Map(lambda x: print(type(x['x'])))\n",
        "\n",
        "  transformed_pcoll | \"PrintEmbeddingShape\" >> beam.Map(lambda x: print(f\"Embedding shape: {len(x['x'])}\"))\n"
      ],
      "metadata": {
        "id": "xyezKuzY_uLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09a07d5-55dc-4544-ea75-39b8105a3e5b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n",
            "Embedding shape: 384\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use the model `sentence-transformers/sentence-t5-large` to generate text embeddings. The model uses only the encoder from a `T5-large model`. The weights are stored in FP16. For more information about the model, see [Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models](https://arxiv.org/abs/2108.08877)."
      ],
      "metadata": {
        "id": "zmQ97UA895W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_location_t5 = tempfile.mkdtemp(prefix='huggingface_t5_')\n",
        "text_embedding_model_name = 'sentence-transformers/sentence-t5-large'\n",
        "embedding_transform = SentenceTransformerEmbeddings(\n",
        "        model_name=text_embedding_model_name, columns=['x'])\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location_t5).with_transform(embedding_transform))\n",
        "\n",
        "  transformed_pcoll | beam.Map(truncate_embeddings) | 'LogOutput' >> beam.Map(print)\n",
        "\n",
        "  transformed_pcoll | \"PrintEmbeddingShape\" >> beam.Map(lambda x: print(f\"Embedding shape: {len(x['x'])}\"))"
      ],
      "metadata": {
        "id": "sK_b6mcY7-Ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2be1dd-72ea-49e5-89ce-1b882e85c9cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': [-0.0317193828523159, -0.005265399813652039, -0.012499183416366577, 0.00018130357784684747, -0.005592408124357462, 0.06207558885216713, -0.01656288281083107, 0.0167048592120409, -0.01239298190921545, 0.03041897714138031]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.015295305289328098, 0.005405726842582226, -0.015631258487701416, 0.022797023877501488, -0.027843449264764786, 0.03968179598450661, -0.004387892782688141, 0.022909151390194893, 0.01015392318367958, 0.04723235219717026]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.03450256213545799, -0.002632762538269162, -0.022460950538516045, -0.011689935810863972, -0.027329981327056885, 0.07293087989091873, -0.03069353476166725, 0.05429817736148834, -0.01308195199817419, 0.017668722197413445]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.02869587577879429, -0.0002648509689606726, -0.007186499424278736, -0.0003750955802388489, 0.012458174489438534, 0.06721009314060211, -0.013404129073023796, 0.03204648941755295, -0.021021844819188118, 0.04968355968594551]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.03241290897130966, 0.006845517549663782, 0.02001815102994442, -0.0057969288900494576, 0.008191823959350586, 0.08160955458879471, -0.009215254336595535, 0.023534387350082397, -0.02034241147339344, 0.0357462577521801]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.04592451825737953, -0.0025395643897354603, -0.01178023498505354, 0.011568977497518063, -0.0029014083556830883, 0.06971456110477448, -0.021167151629924774, 0.015902182087302208, -0.015007994137704372, 0.026213033124804497]}\n",
            "Embedding shape: 10\n",
            "{'x': [0.005221465136855841, -0.002127869985997677, -0.002369001042097807, -0.019337018951773643, 0.023243796080350876, 0.05599674955010414, -0.022721167653799057, 0.024813007563352585, -0.010685156099498272, 0.03624529018998146]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.035339221358299255, 0.010706206783652306, -0.001701260800473392, -0.00862252525985241, 0.006445988081395626, 0.08198338001966476, -0.022678885608911514, 0.01434261817485094, -0.008092232048511505, 0.03345781937241554]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.030748091638088226, 0.009340488351881504, -0.013637947849929333, 0.011183133348822594, -0.013879663310945034, 0.04635031148791313, -0.02409011498093605, 0.02885228581726551, -0.01699882559478283, 0.016723860055208206]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.04079209268093109, -0.008722696453332901, -0.015838177874684334, -0.03141210228204727, -7.106405246304348e-05, 0.08301417529582977, -0.03469115495681763, 0.0026397323235869408, 0.00925522856414318, 0.05415956303477287]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.021568836644291878, 0.003969350829720497, -0.030446073040366173, 0.008231458254158497, -0.01271846517920494, 0.03793857619166374, -0.013524258509278297, -0.038562845438718796, -0.005825811997056007, 0.035052645951509476]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.027544191107153893, -0.017733639106154442, -0.013286476023495197, -0.008328654803335667, -0.011047527194023132, 0.05237516388297081, -0.016948150470852852, 0.028067005798220634, -0.001812086789868772, 0.027241192758083344]}\n",
            "Embedding shape: 10\n",
            "{'x': [-0.034648872911930084, -0.0035212545190006495, -0.010239554569125175, -0.018618229776620865, 0.00409490242600441, 0.062059689313173294, -0.013881966471672058, -0.0008638921426609159, -0.029874084517359734, 0.03353121876716614]}\n",
            "Embedding shape: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MLTransform in read mode\n",
        "\n",
        "In `read` mode, `MLTransform` uses the artifacts generated during `write` mode. In this case, the transform and its attributes are loaded from the saved artifacts. You don't need to specify the artifacts again during `read` mode.\n",
        "\n",
        "In this way, `MLTransform` provides consistent preprocessing steps for training and inference workloads."
      ],
      "metadata": {
        "id": "aPIQzCoF_EBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_content = [\n",
        "    {\n",
        "        'x': 'This is a test sentence'\n",
        "    },\n",
        "    {\n",
        "        'x': 'The park is full of dogs'\n",
        "    },\n",
        "    {\n",
        "        'x': \"Should I sign up for Medicare Part B if I have Veterans' Benefits?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Uses the T5 model to generate text embeddings\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "          pipeline\n",
        "          | \"CreateData\" >> beam.Create(test_content))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(read_artifact_location=artifact_location_t5))\n",
        "\n",
        "  transformed_pcoll | beam.Map(truncate_embeddings) | 'LogOutput' >> beam.Map(print)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCqYeUd3_F3C",
        "outputId": "782fc8a9-b91d-4d0a-9a09-5b99045b57b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': [0.00036313451710157096, -0.03929319977760315, -0.03574873134493828, 0.05015222355723381, 0.04295048117637634, 0.04800170287489891, 0.006883862894028425, -0.02567591704428196, -0.048067063093185425, 0.036534328013658524]}\n",
            "{'x': [-0.053793832659721375, 0.006730600260198116, -0.025130020454525948, 0.04363932088017464, 0.03323192894458771, 0.008803879842162132, -0.015412433072924614, 0.008926985785365105, -0.061175212264060974, 0.04573329910635948]}\n",
            "{'x': [-0.03464885801076889, -0.003521254053339362, -0.010239563882350922, -0.018618224188685417, 0.004094892647117376, 0.062059689313173294, -0.013881963677704334, -0.000863900815602392, -0.029874078929424286, 0.03353121876716614]}\n"
          ]
        }
      ]
    }
  ]
}
